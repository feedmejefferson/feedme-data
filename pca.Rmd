---
title: "Principle Component Analysis"
output: html_notebook
---

When we ran the simple analysis based on food popularity, we were basically just looking at one single dimension of differentiation between the images of food in our catalog. In the world of [Collaborative Filtering](https://en.wikipedia.org/wiki/Collaborative_filtering), item popularity tends to be the single best predictor of the likelihood that an item will be selected. 

Principal Component Analysis is a form of [Dimensionality Reduction](https://en.wikipedia.org/wiki/Dimensionality_reduction) that can be used to convert a high dimension adjacency matrix (the number of search sessions in our case) into a lower dimensional space with each consecutive dimension have less predictive value than the previous. As I mentioned above, the most significant predictor tends to be highly correlated with item popularity. The second most significant predictor then filters out the effect of popularity and accounts for the error. The third most significant predictor is once again independent of the first two and so on. I'll show the top and bottom ten foods rated on a few of the most significant dimensions to illustrate the abstract, but intuitively characteristic differences that they show between foods.

## Building and Adjacency Matrix

Before we can run PCA on an adjacency matrix, we first have to build it. We start with the same process we used to calculate simple popularity -- extract the data from the access log and load it into a dataframe.

```{r, message=FALSE}
source("prep-data.R")
```

Once again, we reshape the access log data frame into a tall/skinny format with one row for each item chosen, and one for each item not chosen, then convert that into a short/wide format with one column for each food item. 

The main difference this time is that we want to keep separate rows in the wide format for each search session. Each search sesssion characterizes a distinct appetite and we want to calculate food similarity based on distinct appetites. 

```{r}
library(reshape2)
melted <- melt(access_log, 
               id.vars=c("search.session"),
               measure.vars=c("chosen", "not.chosen"))

## assign chosen and not chosen positive and negative weightings
map <- c(-1,1)
names(map) <- c("not.chosen","chosen")
melted$weight <- map[as.character(melted$variable)]

counts <- dcast(melted, search.session ~ value, fun.aggregate = length, value.var="weight")
ratings <- dcast(melted, search.session ~ value, fun.aggregate = sum, value.var="weight")
```

Now we just need to convert these dataframes into adjacency matrices -- the first column in the dataframe is the search session id, we'll just remove that and make it the row name on the matrix form.

```{r}
counts.matrix <- as.matrix(counts[,-1])
rownames(counts.matrix) <- counts[,1]

ratings.matrix <- as.matrix(ratings[,-1])
rownames(ratings.matrix) <- ratings[,1]
```

Similar to last time, we'll give each food a weighted rating for each food based on the number of times that food was chosen or not chosen during the search session as a function of the number of times it was available to be chosen.

```{r}
#weighted.matrix <- ratings.matrix
weighted.matrix <- ratings.matrix / (counts.matrix + 1)
```

Here's a small sample of what the adjacency matrix looks like:

```{r}
weighted.matrix[1:5,1:5]
```

Now we can use [Singular Value Decomposition](https://en.wikipedia.org/wiki/Singular-value_decomposition) to perform our PCA on the adjacency matrix.

```{r}
dvu <- svd(weighted.matrix)
```

The `d` component of our SVD output is a vector containing the coefficients from the diagonal matrix. Basically, it tells us the relative signficance of each of the extracted dimensions:

```{r}
dvu$d[1:10]
```
We can see from the coefficents, that the second dimension is nearly as significant as the first. There's a bit of a drop after that followed by a number of additional characteristics/dimensions of similarly ranked significance.

## Visualizing the Results

The `v` component of our SVD output is the right decompsed matrix from our singular value decomposition. The each column of this matrix will rank all of our foods on a different dimension -- the first column being the most significant of those dimensions. We can visualize each of these dimensions in the same way that we visualized popularith -- by displaying the top and bottom ten foods for each dimension.

> Note, in this case, top and bottom might be better referred to as right and left since the positive and negative values on these dimensions convey no specific meaning in terms of "betterness". The top ten foods are simply the most DIFFERENT from the bottom ten on this abstract characteristic dimension.

### Dimension 1 

```{r}
rownames(dvu$v) <- colnames(weighted.matrix)
v <- dvu$v[,1]
ordered.ratings <- v[order(v)]
top10 <- tail(names(ordered.ratings),10)
bottom10 <- head(names(ordered.ratings),10)
```


#### Top 10

```{r}
library(knitr)
## Note, this assumes that the images are sitting in a folder of the parent 
## directory named images
top10.images=paste("../images/",top10,sep = "")
include_graphics(top10.images)
```

### Bottom 10


```{r}
bottom10.images=paste("../images/",bottom10,sep = "")
include_graphics(bottom10.images)
```

### Dimension 2

```{r}
v <- dvu$v[,2]
ordered.ratings <- v[order(v)]
top10 <- tail(names(ordered.ratings),10)
bottom10 <- head(names(ordered.ratings),10)
```


#### Top 10

```{r}
top10.images=paste("../images/",top10,sep = "")
include_graphics(top10.images)
```

### Bottom 10


```{r}
bottom10.images=paste("../images/",bottom10,sep = "")
include_graphics(bottom10.images)
```

### Dimension 3

```{r}
v <- dvu$v[,3]
ordered.ratings <- v[order(v)]
top10 <- tail(names(ordered.ratings),10)
bottom10 <- head(names(ordered.ratings),10)
```


#### Top 10

```{r}
top10.images=paste("../images/",top10,sep = "")
include_graphics(top10.images)
```

### Bottom 10


```{r}
bottom10.images=paste("../images/",bottom10,sep = "")
include_graphics(bottom10.images)
```

### Dimension 4

```{r}
v <- dvu$v[,4]
ordered.ratings <- v[order(v)]
top10 <- tail(names(ordered.ratings),10)
bottom10 <- head(names(ordered.ratings),10)
```


#### Top 10

```{r}
top10.images=paste("../images/",top10,sep = "")
include_graphics(top10.images)
```

### Bottom 10


```{r}
bottom10.images=paste("../images/",bottom10,sep = "")
include_graphics(bottom10.images)
```

### Dimension 5

```{r}
v <- dvu$v[,5]
ordered.ratings <- v[order(v)]
top10 <- tail(names(ordered.ratings),10)
bottom10 <- head(names(ordered.ratings),10)
```


#### Top 10

```{r}
top10.images=paste("../images/",top10,sep = "")
include_graphics(top10.images)
```

### Bottom 10


```{r}
bottom10.images=paste("../images/",bottom10,sep = "")
include_graphics(bottom10.images)
```


